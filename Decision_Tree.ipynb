{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6363f165",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ea881",
   "metadata": {},
   "source": [
    "### The following codes show the performance of the test and train data using Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d02cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Read the data\n",
    "excel_file = \"/Users/mehmetsiddik/Desktop/CsPbCI3_modified.xlsx\"\n",
    "data = pd.read_excel(excel_file)\n",
    "\n",
    "# Identify and one-hot encode categorical columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded = one_hot_encoder.fit_transform(data[categorical_columns])\n",
    "one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# Replace categorical columns with one-hot encoded columns\n",
    "data_encoded = data.drop(categorical_columns, axis=1)\n",
    "data_encoded = pd.concat([data_encoded, one_hot_encoded_df], axis=1)\n",
    "\n",
    "# Target variables\n",
    "targets = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "\n",
    "# Initialize results dictionaries\n",
    "results = {}\n",
    "predictions = {}\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"Evaluating target: {target}\")\n",
    "    X = data_encoded.drop(target, axis=1)\n",
    "    y = data_encoded[target]\n",
    "\n",
    "    # Fill missing values with the median\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    X = pd.DataFrame(imp.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Decision Tree Regressor with randomized search for hyperparameter tuning\n",
    "    param_dist = {\n",
    "        'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    dtr = DecisionTreeRegressor(random_state=42)\n",
    "    random_search = RandomizedSearchCV(dtr, param_dist, cv=5, n_iter=10, random_state=42, verbose=1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model from random search\n",
    "    best_model = random_search.best_estimator_\n",
    "    predictions_train = best_model.predict(X_train)\n",
    "    predictions_test = best_model.predict(X_test)\n",
    "\n",
    "    # Store predictions\n",
    "    predictions[target] = {\n",
    "        'y_test': y_test,\n",
    "        'predictions_test': predictions_test\n",
    "    }\n",
    "\n",
    "    # Performance metrics\n",
    "    results[target] = {\n",
    "        'Train R2': r2_score(y_train, predictions_train),\n",
    "        'Test R2': r2_score(y_test, predictions_test),\n",
    "        'Train RMSE': np.sqrt(mean_squared_error(y_train, predictions_train)),\n",
    "        'Test RMSE': np.sqrt(mean_squared_error(y_test, predictions_test)),\n",
    "        'Train MAE': mean_absolute_error(y_train, predictions_train),\n",
    "        'Test MAE': mean_absolute_error(y_test, predictions_test)\n",
    "    }\n",
    "\n",
    "    # Print performance metrics\n",
    "    print(\"Performance for train data:\")\n",
    "    print(\"R2:\", r2_score(y_train, predictions_train))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_train, predictions_train)))\n",
    "    print(\"MAE:\", mean_absolute_error(y_train, predictions_train))\n",
    "\n",
    "    print(\"Performance for test data:\")\n",
    "    print(\"R2:\", r2_score(y_test, predictions_test))\n",
    "    print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, predictions_test)))\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, predictions_test))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ea902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define figure and axes for subplots\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# Define the titles for the plots\n",
    "titles = ['size_nm', 'S_abs_nm_Y1', 'PL']\n",
    "\n",
    "# Loop through the rows and create the plots for sample numbers and observed vs predicted\n",
    "for i, target in enumerate(targets):\n",
    "    y_test = predictions[target]['y_test']\n",
    "    predictions_test = predictions[target]['predictions_test']\n",
    "    \n",
    "    # Plot (a): Sample Number vs Predicted Values\n",
    "    sns.scatterplot(x=np.arange(1, len(y_test) + 1), y=y_test.values, ax=axs[i, 0], label='Observed', color='red', s=100)\n",
    "    sns.scatterplot(x=np.arange(1, len(y_test) + 1), y=predictions_test, ax=axs[i, 0], label='Predicted', color='#4363d8', s=100)\n",
    "    axs[i, 0].set(xlabel='Sample Number', ylabel='Values (nm)', title=f'{titles[i]}')\n",
    "    axs[i, 0].legend()\n",
    "\n",
    "    # Plot (b): Observed vs Predicted Values\n",
    "    residuals = y_test.values - predictions_test\n",
    "    sns.scatterplot(x=y_test.values, y=predictions_test, hue=residuals, ax=axs[i, 1], palette='Reds', s=100)\n",
    "    axs[i, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "    axs[i, 1].set(xlabel='Observed values (nm)', ylabel='Predicted values (nm)', title=f'{titles[i]}')\n",
    "    axs[i, 1].get_legend().remove()\n",
    "\n",
    "# Adjust the layout to make room for the suptitle\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b1671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
